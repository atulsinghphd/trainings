{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"background-color: #99CD4E; text-align:center; vertical-align: middle; padding:40px 0;\"> \n",
    "  <h1 style=\"color: white;\"> *Text Similarity* </h1>.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #99CD4E; padding:5px 0;\"> \n",
    "  <h2 style=\"color: white;\"> *Text Similarity Use Cases* </h1>\n",
    " </div>\n",
    " \n",
    "Find and eliminate duplicate documents to focus on key issues, and save time. For example, \n",
    "\n",
    "- eliminate duplicate alerts in network management.  \n",
    "- remove duplicate news items for analsysts.\n",
    "\n",
    "\n",
    "Finding similar items for recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #99CD4E; padding:5px 0;\"> \n",
    "  <h2 style=\"color: white;\"> *Similarity Metric* </h1>\n",
    " </div>\n",
    "\n",
    "See [Mining of Massive Datasets](http://infolab.stanford.edu/~ullman/mmds/ch3.pdf) Chapter 3.5 for text similarity measures\n",
    "\n",
    "\n",
    "Given two vectors _*X*_ and _*y*_ with _*p*_ dimensions the distance between them is defined as follows:\n",
    "\n",
    "_**Eulidean Distance**_\n",
    "\n",
    "$$\\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2  + \\ldots + (x_p - y_p)^2  }$$\n",
    "\n",
    "_**Cosine Similarity**_\n",
    "\n",
    "$$\\frac{\\sum\\limits_{k = 1}^{p} xy }{ \\sqrt{\\sum\\limits_{k = 1}^{p} x^2} \\sqrt{\\sum\\limits_{k = 1}^{p} y^2} }  $$\n",
    "\n",
    "cosine similarity gives distance 1 when items are close, and -1 when items are apart.\n",
    "\n",
    "_**Jaccard Distance**_\n",
    "\n",
    "$$1 - \\frac{| x \\cap y |}{| x \\cup y |}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get book text\n",
    "\n",
    "NLTK includes a small selection of texts from the Project Gutenberg electronic text archive which we are going to use in this exercse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = ['austen-emma.txt', 'austen-persuasion.txt','austen-sense.txt',\n",
    "         'carroll-alice.txt','shakespeare-caesar.txt','shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-emma.txt\n",
      "[('mr', 1153), ('emma', 865), ('could', 837), ('would', 820), ('mrs', 699), ('miss', 599), ('must', 567), ('harriet', 506), ('much', 486), ('said', 484)]\n",
      "austen-persuasion.txt\n",
      "[('anne', 497), ('could', 451), ('would', 355), ('captain', 303), ('mrs', 291), ('elliot', 289), ('mr', 256), ('one', 238), ('must', 228), ('wentworth', 218)]\n",
      "austen-sense.txt\n",
      "[('elinor', 685), ('could', 578), ('marianne', 566), ('mrs', 530), ('would', 515), ('said', 397), ('every', 377), ('one', 331), ('much', 290), ('must', 283)]\n",
      "carroll-alice.txt\n",
      "[('said', 462), ('alice', 398), ('little', 128), ('one', 104), ('know', 88), ('like', 85), ('went', 83), ('would', 83), ('could', 77), ('queen', 75)]\n",
      "shakespeare-caesar.txt\n",
      "[('caesar', 190), ('brutus', 161), ('bru', 153), ('haue', 148), ('shall', 125), ('thou', 115), ('cassi', 107), ('cassius', 85), ('antony', 75), ('come', 74)]\n",
      "shakespeare-hamlet.txt\n",
      "[('ham', 337), ('lord', 211), ('haue', 178), ('king', 172), ('thou', 107), ('shall', 107), ('come', 104), ('let', 104), ('hamlet', 100), ('good', 98)]\n",
      "shakespeare-macbeth.txt\n",
      "[('macb', 137), ('haue', 122), ('thou', 90), ('enter', 81), ('shall', 68), ('vpon', 62), ('macbeth', 62), ('thee', 61), ('macd', 58), ('th', 57)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "for book in books:\n",
    "    print(book)\n",
    "    words = gutenberg.words(book)\n",
    "    fd = nltk.FreqDist(w.lower() for w in words if w.lower() not in stopwords if w.isalpha())\n",
    "    print(fd.most_common(10))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert text into tf-idf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n"
     ]
    }
   ],
   "source": [
    "print(type(gutenberg.sents('austen-emma.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_text = []\n",
    "for book in books:\n",
    "    total_text.append(gutenberg.raw(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_total_text = tfidf_vectorizer.fit_transform(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tfidf_total_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 15812)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.shape(tfidf_total_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Compute cosine similarity matrix \n",
    "\n",
    "cosine_similarity(...) create a square matrix in which the number of rows and columns is equal to the number of documents. dist[i, j] gives the cosine similarity between i and j titles.\n",
    "\n",
    "cosine similarity gives distance 1 when items are close, and -1 when items are aprt. In the clustering algorithms higher the distance means that items are similar. Hence, we subtract the computed distance from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist_matrix = 1 - cosine_similarity(tfidf_total_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find closest match for each book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.33226763e-15,   6.01504152e-01,   6.42827294e-01,\n",
       "          8.42037481e-01,   9.27488486e-01,   9.21508140e-01,\n",
       "          9.21809453e-01],\n",
       "       [  6.01504152e-01,   0.00000000e+00,   6.69388161e-01,\n",
       "          8.52648683e-01,   9.29014624e-01,   9.20352323e-01,\n",
       "          9.13800868e-01],\n",
       "       [  6.42827294e-01,   6.69388161e-01,  -4.44089210e-16,\n",
       "          8.46323063e-01,   9.32399745e-01,   9.23216094e-01,\n",
       "          9.22817889e-01],\n",
       "       [  8.42037481e-01,   8.52648683e-01,   8.46323063e-01,\n",
       "          0.00000000e+00,   9.51557089e-01,   9.30205766e-01,\n",
       "          9.38386775e-01],\n",
       "       [  9.27488486e-01,   9.29014624e-01,   9.32399745e-01,\n",
       "          9.51557089e-01,   3.33066907e-16,   6.73658270e-01,\n",
       "          6.30364873e-01],\n",
       "       [  9.21508140e-01,   9.20352323e-01,   9.23216094e-01,\n",
       "          9.30205766e-01,   6.73658270e-01,  -2.22044605e-15,\n",
       "          5.70279666e-01],\n",
       "       [  9.21809453e-01,   9.13800868e-01,   9.22817889e-01,\n",
       "          9.38386775e-01,   6.30364873e-01,   5.70279666e-01,\n",
       "          2.22044605e-16]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.60150415,  0.64282729,  0.84203748,  0.92748849,\n",
       "         0.92150814,  0.92180945],\n",
       "       [ 0.60150415,  1.        ,  0.66938816,  0.85264868,  0.92901462,\n",
       "         0.92035232,  0.91380087],\n",
       "       [ 0.64282729,  0.66938816,  1.        ,  0.84632306,  0.93239975,\n",
       "         0.92321609,  0.92281789],\n",
       "       [ 0.84203748,  0.85264868,  0.84632306,  1.        ,  0.95155709,\n",
       "         0.93020577,  0.93838677],\n",
       "       [ 0.92748849,  0.92901462,  0.93239975,  0.95155709,  1.        ,\n",
       "         0.67365827,  0.63036487],\n",
       "       [ 0.92150814,  0.92035232,  0.92321609,  0.93020577,  0.67365827,\n",
       "         1.        ,  0.57027967],\n",
       "       [ 0.92180945,  0.91380087,  0.92281789,  0.93838677,  0.63036487,\n",
       "         0.57027967,  1.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hack to ensure that diganol with self distance is not minimum value\n",
    "n = len(dist_matrix)\n",
    "dist_matrix[range(n), range(n)] = 1\n",
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dist_matrix_data_frame = pd.DataFrame(dist_matrix, columns=books, index=books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>austen-emma.txt</th>\n",
       "      <th>austen-persuasion.txt</th>\n",
       "      <th>austen-sense.txt</th>\n",
       "      <th>carroll-alice.txt</th>\n",
       "      <th>shakespeare-caesar.txt</th>\n",
       "      <th>shakespeare-hamlet.txt</th>\n",
       "      <th>shakespeare-macbeth.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>austen-emma.txt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601504</td>\n",
       "      <td>0.642827</td>\n",
       "      <td>0.842037</td>\n",
       "      <td>0.927488</td>\n",
       "      <td>0.921508</td>\n",
       "      <td>0.921809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austen-persuasion.txt</th>\n",
       "      <td>0.601504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.852649</td>\n",
       "      <td>0.929015</td>\n",
       "      <td>0.920352</td>\n",
       "      <td>0.913801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austen-sense.txt</th>\n",
       "      <td>0.642827</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846323</td>\n",
       "      <td>0.932400</td>\n",
       "      <td>0.923216</td>\n",
       "      <td>0.922818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carroll-alice.txt</th>\n",
       "      <td>0.842037</td>\n",
       "      <td>0.852649</td>\n",
       "      <td>0.846323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951557</td>\n",
       "      <td>0.930206</td>\n",
       "      <td>0.938387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare-caesar.txt</th>\n",
       "      <td>0.927488</td>\n",
       "      <td>0.929015</td>\n",
       "      <td>0.932400</td>\n",
       "      <td>0.951557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673658</td>\n",
       "      <td>0.630365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare-hamlet.txt</th>\n",
       "      <td>0.921508</td>\n",
       "      <td>0.920352</td>\n",
       "      <td>0.923216</td>\n",
       "      <td>0.930206</td>\n",
       "      <td>0.673658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare-macbeth.txt</th>\n",
       "      <td>0.921809</td>\n",
       "      <td>0.913801</td>\n",
       "      <td>0.922818</td>\n",
       "      <td>0.938387</td>\n",
       "      <td>0.630365</td>\n",
       "      <td>0.570280</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         austen-emma.txt  austen-persuasion.txt  \\\n",
       "austen-emma.txt                 1.000000               0.601504   \n",
       "austen-persuasion.txt           0.601504               1.000000   \n",
       "austen-sense.txt                0.642827               0.669388   \n",
       "carroll-alice.txt               0.842037               0.852649   \n",
       "shakespeare-caesar.txt          0.927488               0.929015   \n",
       "shakespeare-hamlet.txt          0.921508               0.920352   \n",
       "shakespeare-macbeth.txt         0.921809               0.913801   \n",
       "\n",
       "                         austen-sense.txt  carroll-alice.txt  \\\n",
       "austen-emma.txt                  0.642827           0.842037   \n",
       "austen-persuasion.txt            0.669388           0.852649   \n",
       "austen-sense.txt                 1.000000           0.846323   \n",
       "carroll-alice.txt                0.846323           1.000000   \n",
       "shakespeare-caesar.txt           0.932400           0.951557   \n",
       "shakespeare-hamlet.txt           0.923216           0.930206   \n",
       "shakespeare-macbeth.txt          0.922818           0.938387   \n",
       "\n",
       "                         shakespeare-caesar.txt  shakespeare-hamlet.txt  \\\n",
       "austen-emma.txt                        0.927488                0.921508   \n",
       "austen-persuasion.txt                  0.929015                0.920352   \n",
       "austen-sense.txt                       0.932400                0.923216   \n",
       "carroll-alice.txt                      0.951557                0.930206   \n",
       "shakespeare-caesar.txt                 1.000000                0.673658   \n",
       "shakespeare-hamlet.txt                 0.673658                1.000000   \n",
       "shakespeare-macbeth.txt                0.630365                0.570280   \n",
       "\n",
       "                         shakespeare-macbeth.txt  \n",
       "austen-emma.txt                         0.921809  \n",
       "austen-persuasion.txt                   0.913801  \n",
       "austen-sense.txt                        0.922818  \n",
       "carroll-alice.txt                       0.938387  \n",
       "shakespeare-caesar.txt                  0.630365  \n",
       "shakespeare-hamlet.txt                  0.570280  \n",
       "shakespeare-macbeth.txt                 1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_matrix_data_frame['Minimum'] = dist_matrix_data_frame.apply(lambda x: x.argmin(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "austen-emma.txt              austen-persuasion.txt\n",
       "austen-persuasion.txt              austen-emma.txt\n",
       "austen-sense.txt                   austen-emma.txt\n",
       "carroll-alice.txt                  austen-emma.txt\n",
       "shakespeare-caesar.txt     shakespeare-macbeth.txt\n",
       "shakespeare-hamlet.txt     shakespeare-macbeth.txt\n",
       "shakespeare-macbeth.txt     shakespeare-hamlet.txt\n",
       "Name: Minimum, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix_data_frame['Minimum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try to repeat this exercise with all the books, and see which books are closest to them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repeat this exercise with Eucledian distance and evalaute the results especially when compared to cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"background-color: #99CD4E; text-align:center; vertical-align: middle; padding:40px 0;\"> \n",
    "  <h1 style=\"color: white;\"> *The End* </h1>.\n",
    " </div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
